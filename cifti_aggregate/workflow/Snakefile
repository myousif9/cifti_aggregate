#---- begin snakebids boilerplate ----------------------------------------------

import snakebids
from snakebids import bids
import snakebids.utils.snakemake_io as sio
import os
from os.path import join
import pandas as pd


configfile: workflow.source_path('../config/snakebids.yml')

# Get input wildcards
inputs = snakebids.generate_inputs(
    bids_dir=config["bids_dir"],
    pybids_inputs=config["pybids_inputs"],
    pybids_database_dir=config.get("pybids_db_dir"),
    pybids_reset_database=config.get("pybids_db_reset"),
    derivatives=config.get("derivatives", None),
    participant_label=config.get("participant_label", None),
    exclude_participant_label=config.get("exclude_participant_label", None),
    use_bids_inputs=True,
)

# print(inputs.input_zip_lists['metric'])

#this adds constraints to the bids naming
wildcard_constraints:  **snakebids.get_wildcard_constraints(config['pybids_inputs'])


#---- end snakebids boilerplate ------------------------------------------------

zip_list_filter = snakebids.filter_list(
    inputs.input_zip_lists['metric'],
    {
        'den' : config['density'],
        'label' : config['label'],
        'space' : config['space']
        })

zip_list_filter = pd.DataFrame(zip_list_filter).sort_values(by='subject').to_dict('list')

rule aggregate_metric:
    input:
        metric = expand(
            inputs.input_path['metric'],
            subject = zip_list_filter['subject'],
            allow_missing=True
            )
    params:
        merge_opt = lambda wildcards, input: " ".join(
            [f"-cifti {cifti}" for cifti in input.metric]
        ),
        setmap_opt = lambda wildcards, input: " ".join(
            [f"-map {idx+1} {subj}" for idx, subj in enumerate(zip_list_filter['subject'])]
        ),
    output:
        metric_group = bids(
            root = 'results',
            datatype = 'surf',
            subject = '{subject}',
            space = '{space}',
            den = '{den}',
            label = '{label}',
            suffix='{metric}.dscalar.nii'
            ),
        
    group: 'aggregate'
    container: config['singularity']['autotop']
    threads: 16
    resources:
        mem_mb = 64000,
        time = 180
    shell: 
        """
        wb_command -cifti-merge {output.metric_group} {params.merge_opt}
        wb_command -set-map-names {output.metric_group} {params.setmap_opt}
        """

rule make_df:
    params: 
        subjects = zip_list_filter['subject'],
    output: 
        metric_df = bids(
            root = 'results',
            datatype = 'surf',
            subject = '{subject}',
            space = '{space}',
            den = '{den}',
            label = '{label}',
            suffix='{metric}.csv'
            ),
    group: 'aggregate'      
    run: 
        df = pd.DataFrame({'subject':params.subjects})
        df.to_csv(output.metric_df, index=False)

metric_suffix = inputs.input_path['metric'].split('_')[-1].replace('.dscalar.nii','')

rule all:
    input:
        expand(
            expand(
                rules.aggregate_metric.output.metric_group,
                subject = config['group_name'],
                metric = metric_suffix if config['metric_name'] == False else config['metric_name'],
                allow_missing=True
            ),
            zip,
            **zip_list_filter
        ),
        expand(
            expand(
                rules.make_df.output.metric_df,
                subject = config['group_name'],
                metric = metric_suffix if config['metric_name'] == False else config['metric_name'],
                allow_missing=True
            ),
            zip,
            **zip_list_filter
        )
    default_target: True